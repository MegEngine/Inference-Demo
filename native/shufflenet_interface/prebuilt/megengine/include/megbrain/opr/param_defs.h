// generated by gen_param_defs.py for 469e143ef961acb9b6cc3b3144ee2c8356e285ec3e50e955ba298d9b5964aac4
#pragma once
#include "megdnn/dtype.h"
#include <stdint.h>
#include <string.h>
namespace megdnn {
namespace param {
struct DType {
    static MEGDNN_CONSTEXPR uint32_t TAG = 3384694015u;
    union { struct {
    DTypeEnum dtype;
    }; };
    DType(DTypeEnum dtype_=DTypeEnum::Byte) {
        memset(this, 0, sizeof(*this));
        this->dtype = dtype_;
    }
};

struct PersistentOutputStorage {
    static MEGDNN_CONSTEXPR uint32_t TAG = 2701766423u;
    union { struct {
    /*!
     * This is used for controlling memory sharing. Multiple
     * ``PersistentOutputStorage'' oprs with the same ``share_key'' would share
     * underlying tensor storage. Note that the value ``-1'' is treated
     * specially: storage of oprs with this key would be private and would not
     * be shared with any other opr.
     */
    int32_t share_key;
    }; };
    PersistentOutputStorage(int32_t share_key_=-1) {
        memset(this, 0, sizeof(*this));
        this->share_key = share_key_;
    }
};

//! optinal axis: axis == -1 means no axis
struct OptionalAxis {
    static MEGDNN_CONSTEXPR uint32_t TAG = 652773454u;
    union { struct {
    int32_t axis;
    }; };
    OptionalAxis(int32_t axis_=-1) {
        memset(this, 0, sizeof(*this));
        this->axis = axis_;
    }
};

//! optinal axis: axis == MAX_NDIM means no axis
struct OptionalAxisV1 {
    static MEGDNN_CONSTEXPR uint32_t TAG = 2892002433u;
    static constexpr int32_t MAX_NDIM = 7;
    static constexpr int32_t INVALID_AXIS = MAX_NDIM;
    union { struct {
    int32_t axis;
    }; };
    OptionalAxisV1(int32_t axis_=INVALID_AXIS) {
        memset(this, 0, sizeof(*this));
        this->axis = axis_;
    }
};

//! specify how to select an algorithm for an operator
struct ExecutionPolicy {
    static MEGDNN_CONSTEXPR uint32_t TAG = 2482374207u;
    enum class Strategy: uint32_t {
        //! use heuristic to choose the fastest algorithm
        HEURISTIC = 0,
        /*!
         * use heuristic to choose the fastest algorithm, and the chosen
         * algorithm is reproducible
         */
        HEURISTIC_REPRODUCIBLE = 1,
        //! run possible algorithms on real device to find the best
        PROFILE = 2,
        //! the fastest of profile result that is also reproducible
        PROFILE_REPRODUCIBLE = 3,
        //! use profile result and heuristic to choose the fastest algorithm
        PROFILE_HEURISTIC = 4
    };
    static MEGDNN_CONSTEXPR uint32_t STRATEGY_NR_MEMBER = 5;
    union { struct {
    Strategy strategy;
    //! workspace limit in bytes
    alignas(sizeof(uint64_t)) uint64_t workspace_limit;
    }; };
    ExecutionPolicy(Strategy strategy_=Strategy::HEURISTIC, uint64_t workspace_limit_=18446744073709551615ull) {
        memset(this, 0, sizeof(*this));
        this->strategy = strategy_;
        this->workspace_limit = workspace_limit_;
    }
};

struct AssertEqual {
    static MEGDNN_CONSTEXPR uint32_t TAG = 2723797575u;
    union { struct {
    /*!
     * max allowed error; error is defined as the minimal of absolute and
     * relative error
     */
    float maxerr;
    //! whether to print maxerr to stdout during opr exec
    bool verbose;
    }; };
    AssertEqual(float maxerr_=0.0001, bool verbose_=false) {
        memset(this, 0, sizeof(*this));
        this->maxerr = maxerr_;
        this->verbose = verbose_;
    }
};

//! collective communication between multiple computing nodes on localhost
struct CollectiveComm {
    static MEGDNN_CONSTEXPR uint32_t TAG = 302993407u;
    //! mode of collective communication
    enum class Mode: uint32_t {
        //! reduce by sum to output computing node
        REDUCE_SUM = 0,
        //! copy input value to each output computing node
        BROADCAST = 1,
        //! each output comp node gets the concatenated value of all inputs
        ALL_GATHER = 2,
        //! reduce inputs by sum and each output gets one part of it
        REDUCE_SCATTER_SUM = 3,
        //! every output gets the sum of all inputs
        ALL_REDUCE_SUM = 4,
        //! every output gets the max of all inputs
        ALL_REDUCE_MAX = 5,
        //! every output gets the min of all inputs
        ALL_REDUCE_MIN = 6,
        //! every output gets the prod of all inputs
        ALL_REDUCE_PROD = 7,
        //! concat inputs to one node
        GATHER = 8,
        //! scatter input to each output computing node
        SCATTER = 9,
        //! scatter inputs and gather them on each computing node
        ALL_TO_ALL = 10
    };
    static MEGDNN_CONSTEXPR uint32_t MODE_NR_MEMBER = 11;
    union { struct {
    Mode mode;
    }; };
    CollectiveComm(Mode mode_=Mode::REDUCE_SUM) {
        memset(this, 0, sizeof(*this));
        this->mode = mode_;
    }
};

/*!
 * HACK: The tag of this param def is actually used for another non-generated
 * param def SerializedDType, the sole purpose of this param def is to provide
 * a spare tag. Do not use.
 */
struct FakeSerializedDType {
    static MEGDNN_CONSTEXPR uint32_t TAG = 3091029830u;
};

/*!
 * evaluate a predicate and branch keys to setup ExecutionMask objects with
 * associated predicate proxy vars (PPVs)
 */
struct CondExecPred {
    static MEGDNN_CONSTEXPR uint32_t TAG = 2266180791u;
    //! how to compare predicate var with branch keys
    enum class Mode: uint32_t {
        /*!
         * The outputs correspond to branch keys, and the one which equals
         * predicate would be activated. This behaves like a case-statement in
         * many languages.
         */
        CASE = 0,
        /*!
         * like :attr:`CASE`, but add an extra output that would be activated
         * if no branch is matched
         */
        CASE_FALLBACK = 1,
        /*!
         * One more outputs would be produced than the number of branch keys,
         * representing the interval in which the predicate var fits in. The
         * intervals are defined as :math:`(-\\infty, k_0), [k_0, k_1),
         * \\ldots, [k_{n-2}, k_{n-1}), [k_{n-1}, \infty)`. The keys must be
         * given in ascending order.
         */
        PIECEWISE = 2
    };
    static MEGDNN_CONSTEXPR uint32_t MODE_NR_MEMBER = 3;
    union { struct {
    Mode mode;
    //! threshold for checking equality of float point values
    float eps;
    }; };
    CondExecPred(Mode mode_=Mode::CASE, float eps_=0.0001) {
        memset(this, 0, sizeof(*this));
        this->mode = mode_;
        this->eps = eps_;
    }
};

//! compute a logical function over a set of PPVs
struct CondExecPredLogical {
    static MEGDNN_CONSTEXPR uint32_t TAG = 1659479472u;
    enum class Mode: uint32_t {
        //! logical or
        OR = 0,
        //! logical and
        AND = 1,
        //! exclusive-or
        XOR = 2,
        //! not or(inputs)
        NOR = 3,
        //! not and(inputs)
        NAND = 4,
        //! not xor(inputs)
        XNOR = 5
    };
    static MEGDNN_CONSTEXPR uint32_t MODE_NR_MEMBER = 6;
    union { struct {
    Mode mode;
    }; };
    CondExecPredLogical(Mode mode_=Mode::OR) {
        memset(this, 0, sizeof(*this));
        this->mode = mode_;
    }
};

/*!
 * add ExecutionMask of the input PPV to this opr and readers of the outputs of
 * this opr
 */
struct CondExecMark {
    static MEGDNN_CONSTEXPR uint32_t TAG = 3321237194u;
    //! mode for computing the gradient
    enum class GradMode: uint32_t {
        //! normal gradient mode: sum all the activated components
        SUM = 0,
        /*!
         * use :attr:`CondExecMerge.SUM_COND_OUT` mode so oprs that depend on
         * the gradient opr would not be executed if the forward var is not
         * used.
         */
        SUM_COND_OUT = 1
    };
    static MEGDNN_CONSTEXPR uint32_t GRADMODE_NR_MEMBER = 2;
    /*!
     * static inference option. **Note:** This is a workaround: since
     * currently static inference in MegBrain does not take conditional
     * execution into account, this option can be used to bypass static
     * inference errors. This is currently only used by automatically
     * generated gradient oprs.
     */
    enum class StaticInfer: uint32_t {
        //! enable both shape and value inference
        SHAPE_VALUE = 0,
        //! only enable shape inference (disable value inference)
        SHAPE_ONLY = 1,
        //! disable both shape and value inference
        NONE = 2
    };
    static MEGDNN_CONSTEXPR uint32_t STATICINFER_NR_MEMBER = 3;
    union { struct {
    GradMode grad_mode;
    StaticInfer static_infer;
    }; };
    CondExecMark(GradMode grad_mode_=GradMode::SUM, StaticInfer static_infer_=StaticInfer::SHAPE_VALUE) {
        memset(this, 0, sizeof(*this));
        this->grad_mode = grad_mode_;
        this->static_infer = static_infer_;
    }
};

//! merge multiple conditional execution branches
struct CondExecMerge {
    static MEGDNN_CONSTEXPR uint32_t TAG = 1835965897u;
    enum class Mode: uint32_t {
        /*!
         * copy the var whose mask is activated to the output, requiring that
         * exactly one branch is active
         */
        EXACT_ONE = 0,
        /*!
         * like :attr:`EXACT_ONE` with the requirement that all branches have
         * the same shape, so shape inference can be easier
         */
        EXACT_ONE_SAME_SHAPE = 1,
        /*!
         * sum all the active branches into output var; require all branches to
         * have the same shape. Extra shape vars are needed in this mod, so the
         * outputs can be initialized to zero when no input is active (and
         * their shapes are probably unknown).
         */
        SUM = 2,
        /*!
         * like :attr:`SUM` but also add an ExecutionMask to the readers of
         * output vars, so they would be skipped if  no branch is taken
         */
        SUM_COND_OUT = 3
    };
    static MEGDNN_CONSTEXPR uint32_t MODE_NR_MEMBER = 4;
    union { struct {
    //! number of output vars (i.e. vars per branch)
    uint32_t nr_output;
    Mode mode;
    }; };
    CondExecMerge(uint32_t nr_output_=1, Mode mode_=Mode::EXACT_ONE) {
        memset(this, 0, sizeof(*this));
        this->nr_output = nr_output_;
        this->mode = mode_;
    }
};

} // namespace megdnn
} // namespace param
// vim: syntax=cpp.doxygen
